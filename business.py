# Business logic related to transcription
import os
import warnings
import time
import logging
import subprocess
import json
import shutil
from pathlib import Path
from datetime import timedelta
from PySide6.QtCore import QThread, Signal

try:
    import whisper
except ImportError:  # pragma: no cover - optional dependency
    whisper = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –¥–ª—è –º–æ–¥–µ–ª–µ–π
MODEL_CACHE = {}


class ModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª—è–º–∏."""

    @staticmethod
    def get_model(model_size, backend="whisper"):
        """–ü–æ–ª—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—É—é."""
        cache_key = f"{backend}_{model_size}"

        if cache_key in MODEL_CACHE:
            logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: {cache_key}")
            return MODEL_CACHE[cache_key]

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {cache_key}")

        # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ symlinks –∏ pkg_resources
        os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            if backend == "faster-whisper":
                from faster_whisper import WhisperModel
                import torch

                device = "cuda" if torch.cuda.is_available() else "cpu"
                compute_type = "float16" if device == "cuda" else "int8"

                model = WhisperModel(
                    model_size,
                    device=device,
                    compute_type=compute_type,
                    cpu_threads=os.cpu_count(),
                    num_workers=4,
                )
            else:
                if whisper is None:
                    raise RuntimeError(
                        "whisper package is not installed, –≤—ã–±–µ—Ä–∏—Ç–µ 'faster-whisper'"
                    )
                model = whisper.load_model(model_size)

        MODEL_CACHE[cache_key] = model
        return model

    @staticmethod
    def clear_cache():
        """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏."""
        global MODEL_CACHE
        MODEL_CACHE.clear()
        logger.info("–ö—ç—à –º–æ–¥–µ–ª–µ–π –æ—á–∏—â–µ–Ω")


class FFProbeChecker:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ ffprobe."""

    _is_available = None

    @classmethod
    def is_available(cls):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ffprobe (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)."""
        if cls._is_available is not None:
            return cls._is_available

        try:
            result = subprocess.run(
                ['ffprobe', '-version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            cls._is_available = result.returncode == 0
            if cls._is_available:
                logger.info("ffprobe –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                logger.warning("ffprobe –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        except (subprocess.SubprocessError, FileNotFoundError) as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ ffprobe: {e}")
            cls._is_available = False

        return cls._is_available


class TranscriptionThread(QThread):
    """Thread that performs transcription of multiple files."""

    progress = Signal(int)
    status = Signal(str)
    finished = Signal(str, str)  # file_path, output_path
    error = Signal(str, str)  # file_path, error_message
    current_file = Signal(str)
    overall_progress = Signal(int, int)  # current, total
    benchmark_result = Signal(str, float)  # engine_name, time_per_minute
    file_not_found = Signal(str)  # file_path that was not found

    def __init__(self, file_paths, model_size, output_format="srt", backend="whisper", language="auto"):
        super().__init__()
        self.file_paths = file_paths
        self.model_size = model_size
        self.output_format = output_format
        self.backend = backend
        self.language = language
        self.is_running = True
        self.total_audio_duration = 0
        self.total_processing_time = 0
        self._should_stop = False

    def run(self):
        try:
            self.status.emit("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            try:
                import torch
                device_info = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
            except ImportError:
                device_info = "CPU"

            start_load_time = time.time()

            try:
                model = ModelManager.get_model(self.model_size, self.backend)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                self.error.emit("", f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {str(e)}")
                return

            load_time = time.time() - start_load_time
            self.status.emit(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({device_info}) –∑–∞ {load_time:.1f}—Å")

            total_files = len(self.file_paths)

            for index, file_path in enumerate(self.file_paths):
                if self._should_stop:
                    logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
                    break

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
                if not os.path.exists(file_path):
                    logger.warning(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
                    self.file_not_found.emit(file_path)
                    self.error.emit(file_path, "–§–∞–π–ª –±—ã–ª —É–¥–∞–ª–µ–Ω –∏–ª–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω")
                    continue

                self.current_file.emit(os.path.basename(file_path))
                self.overall_progress.emit(index + 1, total_files)

                try:
                    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
                    audio_duration = self.get_audio_duration(file_path)

                    self.status.emit("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏–µ")
                    self.progress.emit(30)

                    start_time = time.time()

                    if self.backend == "faster-whisper":
                        segments, info = model.transcribe(
                            file_path,
                            language=None if self.language == "auto" else self.language,
                            beam_size=1,
                            vad_filter=True,
                            vad_parameters=dict(
                                min_silence_duration_ms=500,
                            ),
                        )
                        result_segments = [
                            {"start": s.start, "end": s.end, "text": s.text}
                            for s in segments
                        ]
                        if hasattr(info, 'duration') and info.duration:
                            audio_duration = info.duration
                        # Log detected language if auto
                        if self.language == "auto" and hasattr(info, 'language'):
                            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {info.language}")
                    else:
                        result = model.transcribe(
                            file_path,
                            language=None if self.language == "auto" else self.language,
                            fp16=False
                        )
                        result_segments = result["segments"]
                        if "segments" in result and result["segments"]:
                            last_segment = result["segments"][-1]
                            audio_duration = last_segment["end"]
                        # Log detected language if auto
                        if self.language == "auto" and "language" in result:
                            logger.info(f"–û–ø—Ä–µ–¥–µ–ª–µ–Ω —è–∑—ã–∫: {result['language']}")

                    processing_time = time.time() - start_time

                    # –î–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ
                    if audio_duration > 0:
                        self.total_audio_duration += audio_duration
                        self.total_processing_time += processing_time

                    self.progress.emit(80)

                    # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
                    input_path = Path(file_path)
                    if self.output_format == "txt":
                        content = self.create_txt(result_segments)
                        output_path = input_path.with_suffix(".txt")
                    else:
                        content = self.create_srt(result_segments)
                        output_path = input_path.with_suffix(".srt")

                    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
                    try:
                        with open(output_path, "w", encoding="utf-8") as f:
                            f.write(content)
                    except IOError as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞ {output_path}: {e}")
                        self.error.emit(file_path, f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª: {str(e)}")
                        continue

                    self.progress.emit(100)
                    self.finished.emit(file_path, str(output_path))

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}", exc_info=True)
                    self.error.emit(file_path, str(e))

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞
            if self.total_audio_duration > 0 and self.total_processing_time > 0:
                time_per_minute = (self.total_processing_time / self.total_audio_duration) * 60
                self.benchmark_result.emit(self.backend, time_per_minute)

        except Exception as e:
            logger.error(f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –≤ –ø–æ—Ç–æ–∫–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}", exc_info=True)
            self.error.emit("", f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {str(e)}")

    def stop(self):
        """–ú—è–≥–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞."""
        self._should_stop = True
        self.is_running = False
        logger.info("–ó–∞–ø—Ä–æ—à–µ–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏")

    def get_audio_duration(self, file_path):
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö."""
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å ffprobe
        if not FFProbeChecker.is_available():
            logger.warning("ffprobe –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞")
            return 0

        try:
            cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-print_format', 'json',
                '-show_format',
                file_path
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30  # –¢–∞–π–º–∞—É—Ç 30 —Å–µ–∫—É–Ω–¥
            )

            if result.returncode == 0:
                data = json.loads(result.stdout)
                duration = float(data['format']['duration'])
                logger.debug(f"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å {file_path}: {duration}—Å")
                return duration
            else:
                logger.warning(f"ffprobe –≤–µ—Ä–Ω—É–ª –∫–æ–¥ –æ—à–∏–±–∫–∏ {result.returncode} –¥–ª—è {file_path}")
                return 0

        except subprocess.TimeoutExpired:
            logger.error(f"–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è {file_path}")
            return 0
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç ffprobe –¥–ª—è {file_path}: {e}")
            return 0
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è {file_path}: {e}")
            return 0

    def create_srt(self, segments):
        srt_content = ""
        for i, segment in enumerate(segments, 1):
            start_time = self.format_timestamp(segment["start"])
            end_time = self.format_timestamp(segment["end"])
            text = segment["text"].strip()

            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"

        return srt_content

    def create_txt(self, segments):
        """Return plain text without time codes from segments."""
        return "\n".join(segment["text"].strip() for segment in segments)

    def format_timestamp(self, seconds):
        td = timedelta(seconds=seconds)
        hours = td.seconds // 3600
        minutes = (td.seconds % 3600) // 60
        seconds = td.seconds % 60
        milliseconds = td.microseconds // 1000
        return f"{hours:02d}:{minutes:02d}:{seconds:02d},{milliseconds:03d}"


class BenchmarkThread(QThread):
    """Thread that performs benchmark comparison between whisper and faster-whisper."""

    status = Signal(str)
    progress = Signal(int)
    result = Signal(str)
    error = Signal(str)

    def __init__(self, test_file, model_size="tiny"):
        super().__init__()
        self.test_file = test_file
        self.model_size = model_size

    def run(self):
        try:
            results = []

            # –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
            os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
            warnings.filterwarnings("ignore", message="pkg_resources is deprecated")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            try:
                import torch
                device_info = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
                has_gpu = torch.cuda.is_available()
            except ImportError:
                device_info = "CPU"
                has_gpu = False

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º faster-whisper
            try:
                self.status.emit("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Faster-Whisper...")
                self.progress.emit(25)

                model = ModelManager.get_model(self.model_size, "faster-whisper")

                # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏
                self.status.emit("–ü—Ä–æ–≥—Ä–µ–≤ Faster-Whisper...")
                warmup_segments, _ = model.transcribe(
                    self.test_file,
                    language="en",
                    beam_size=1,
                    vad_filter=True,
                )
                _ = list(warmup_segments)

                # –†–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
                self.status.emit("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Faster-Whisper (–æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫)...")
                start_time = time.time()
                segments, info = model.transcribe(
                    self.test_file,
                    language="en",
                    beam_size=1,
                    vad_filter=True,
                )
                _ = list(segments)
                transcribe_time = time.time() - start_time

                audio_duration = info.duration if hasattr(info, 'duration') else 60
                time_per_minute = (transcribe_time / audio_duration) * 60

                results.append(f"üöÄ Faster-Whisper ({device_info}):")
                results.append(f"   –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: {transcribe_time:.2f}—Å")
                results.append(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {time_per_minute:.2f}—Å –Ω–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ")
                results.append(f"   –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {audio_duration / transcribe_time:.1f}x")

            except Exception as e:
                results.append(f"‚ùå Faster-Whisper: {str(e)}")

            self.progress.emit(50)

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π whisper
            if whisper is not None:
                try:
                    self.status.emit("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI Whisper...")
                    self.progress.emit(75)

                    model = ModelManager.get_model(self.model_size, "whisper")

                    # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏
                    self.status.emit("–ü—Ä–æ–≥—Ä–µ–≤ OpenAI Whisper...")
                    _ = model.transcribe(self.test_file, language=None, fp16=False)

                    # –†–µ–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç
                    self.status.emit("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI Whisper (–æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫)...")
                    start_time = time.time()
                    result = model.transcribe(self.test_file, language=None, fp16=False)
                    transcribe_time = time.time() - start_time

                    if result["segments"]:
                        audio_duration = result["segments"][-1]["end"]
                    else:
                        audio_duration = 60

                    time_per_minute = (transcribe_time / audio_duration) * 60

                    results.append(f"\nüê¢ OpenAI Whisper ({device_info}):")
                    results.append(f"   –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è: {transcribe_time:.2f}—Å")
                    results.append(f"   –°–∫–æ—Ä–æ—Å—Ç—å: {time_per_minute:.2f}—Å –Ω–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ")
                    results.append(f"   –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {audio_duration / transcribe_time:.1f}x")

                except Exception as e:
                    results.append(f"\n‚ùå OpenAI Whisper: {str(e)}")
            else:
                results.append(f"\n‚ùå OpenAI Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

            self.progress.emit(100)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
            summary = f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±–µ–Ω—á–º–∞—Ä–∫–∞ (–º–æ–¥–µ–ª—å: {self.model_size})\n"
            summary += f"üìÅ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {os.path.basename(self.test_file)}\n"
            summary += f"üíª –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device_info}\n"
            summary += "‚îÄ" * 50 + "\n"
            summary += "\n".join(results)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            summary += "\n\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
            if not has_gpu:
                summary += "‚Ä¢ –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤ 4-5 —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ GPU (NVIDIA —Å CUDA)\n"
            summary += "‚Ä¢ Faster-Whisper —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö\n"
            summary += "‚Ä¢ –ú–æ–¥–µ–ª—å 'base' –¥–∞–µ—Ç –ª—É—á—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞\n"
            if device_info == "CPU":
                summary += "‚Ä¢ –ù–∞ CPU —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –¥–≤–∏–∂–∫–∞–º–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞\n"

            self.result.emit(summary)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞: {e}", exc_info=True)
            self.error.emit(f"–û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞: {str(e)}")